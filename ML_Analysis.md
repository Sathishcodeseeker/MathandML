# Complete Algorithm Reference

## Tier 1: Production Workhorses (80% of ML models)

### Supervised Learning ‚Äì Tabular Data

**Gradient Boosting (XGBoost / LightGBM / CatBoost) üèÜ**  
- **Usage:** 70‚Äì80% of tabular ML problems  
- **Where:** Finance, e-commerce, insurance, healthcare  
- **Why dominant:** Best accuracy on structured data, fast, handles missing values  
- **Learn priority:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (HIGHEST)

**Logistic Regression**  
- **Usage:** Extremely high  
- **Where:** A/B testing, CTR prediction, baseline models  
- **Why:** Interpretable, fast, reliable, regulation-friendly  
- **Learn priority:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Linear Regression**  
- **Usage:** Very high  
- **Where:** Pricing, forecasting, demand prediction  
- **Why:** Simple, interpretable, good baseline  
- **Learn priority:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Random Forests**  
- **Usage:** High (declining vs. boosting)  
- **Where:** Classification, feature importance, ensembles  
- **Why:** Robust, less overfitting than single trees  
- **Learn priority:** ‚≠ê‚≠ê‚≠ê‚≠ê

**Support Vector Machines (SVM)**  
- **Usage:** Medium (declining)  
- **Where:** Small datasets, text classification (legacy)  
- **Status:** Being replaced by neural networks and boosting  
- **Learn priority:** ‚≠ê‚≠ê (Optional)

---

### Deep Learning ‚Äì Text / NLP

**Transformers (BERT, GPT, T5, etc.) üöÄ**  
- **Usage:** Exploding growth (30%+ of NLP, up from 5% in 2022)  
- **Where:** Chatbots, search, translation, code generation  
- **Approach:** Use pre-trained models via APIs (OpenAI, Anthropic)  
- **Learn priority:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Word Embeddings (Word2Vec, GloVe)**  
- **Usage:** Declining (replaced by transformers)  
- **Where:** Legacy systems, resource-constrained apps  
- **Learn priority:** ‚≠ê‚≠ê (Historical knowledge)

---

### Deep Learning ‚Äì Computer Vision

**Convolutional Neural Networks (CNNs)**  
- **Usage:** Very high in vision tasks  
- **Where:** Manufacturing defects, medical imaging, autonomous vehicles  
- **Approach:** Transfer learning from pre-trained models (ResNet, EfficientNet)  
- **Learn priority:** ‚≠ê‚≠ê‚≠ê‚≠ê

**YOLO / Object Detection**  
- **Usage:** High in specific domains  
- **Where:** Real-time detection, surveillance, autonomous driving  
- **Learn priority:** ‚≠ê‚≠ê‚≠ê (If doing computer vision)

**U-Net / Segmentation Models**  
- **Usage:** Medium‚Äìhigh in specialized domains  
- **Where:** Medical imaging, satellite imagery  
- **Learn priority:** ‚≠ê‚≠ê (Specialized)

---

## Tier 2: Important but Specialized

### Clustering & Unsupervised Learning

**K-Means Clustering**  
- **Usage:** High for clustering  
- **Where:** Customer segmentation, image compression  
- **Why popular:** Simple, fast, interpretable  
- **Learn priority:** ‚≠ê‚≠ê‚≠ê‚≠ê

**DBSCAN (Density-Based Clustering)**  
- **Usage:** Medium‚Äìhigh  
- **Where:** Anomaly detection, geographic data, fraud detection  
- **Advantage:** Finds arbitrary shapes, identifies outliers automatically  
- **Learn priority:** ‚≠ê‚≠ê‚≠ê

**Hierarchical Clustering**  
- **Usage:** Medium  
- **Where:** Taxonomies, dendrograms, biological data  
- **Learn priority:** ‚≠ê‚≠ê

**HDBSCAN**  
- **Usage:** Growing  
- **Where:** Better version of DBSCAN for varying densities  
- **Learn priority:** ‚≠ê‚≠ê (Advanced)

**Gaussian Mixture Models (GMM)**  
- **Usage:** Medium  
- **Where:** Soft clustering, density estimation  
- **Learn priority:** ‚≠ê‚≠ê

---

### Dimensionality Reduction

**Principal Component Analysis (PCA)**  
- **Usage:** Very high  
- **Where:** Feature reduction, visualization, noise reduction  
- **Learn priority:** ‚≠ê‚≠ê‚≠ê‚≠ê

**t-SNE**  
- **Usage:** High for visualization only  
- **Where:** Data visualization, exploratory analysis  
- **Limitation:** Slow, not for feature extraction  
- **Learn priority:** ‚≠ê‚≠ê‚≠ê

**UMAP**  
- **Usage:** Growing (replacing t-SNE)  
- **Where:** Visualization, feature extraction  
- **Advantage:** Faster than t-SNE, preserves global structure  
- **Learn priority:** ‚≠ê‚≠ê‚≠ê

**Autoencoders**  
- **Usage:** Medium  
- **Where:** Dimensionality reduction, anomaly detection, denoising  
- **Learn priority:** ‚≠ê‚≠ê‚≠ê

---

## Metric Selection Guide

**Is it Classification?**  
- **Yes ‚Üí Is data balanced?**  
  - **Yes ‚Üí** Accuracy, F1-Score, ROC-AUC  
  - **No ‚Üí** F1/F2-Score, PR-AUC, MCC  

**No ‚Üí Is it Regression?**  
- **Yes ‚Üí Are outliers important?**  
  - **Yes ‚Üí** RMSE  
  - **No ‚Üí** MAE  

**No ‚Üí Is it Ranking?**  
- **Yes ‚Üí** NDCG, MAP
